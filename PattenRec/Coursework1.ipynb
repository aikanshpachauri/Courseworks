{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18bb69bf-3a11-4dda-bc66-09659a67824f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-20 03:53:07.604177: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-20 03:53:07.604332: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-20 03:53:07.614020: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-20 03:53:07.671179: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-20 03:53:08.857156: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "(X_train, labels_train), (X_test, labels_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "078bd4d9-adde-4093-a618-cdde841e6717",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6020083f-ce8e-47f9-bfe2-c842f7312763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6ce3506bf0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e0af1c2-ecb0-43b4-9a0c-eb5423c6ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 28,28,1)\n",
    "X_test = X_test.reshape(10000, 28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "941155b0-7ab5-4f80-8862-2d576889ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(labels_train, 10) \n",
    "y_test = to_categorical(labels_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba281d2c-e4ff-4155-b525-63d1dcf2c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=15, # Rotating randomly the images up to 25°\n",
    "                             width_shift_range=0.05, # Moving the images from left to right\n",
    "                             height_shift_range=0.05, # Then from top to bottom\n",
    "                             shear_range=0.10, \n",
    "                             zoom_range=0.02, # Zooming randomly up to 20%\n",
    "                             zca_whitening=False,\n",
    "                             horizontal_flip=False, \n",
    "                             vertical_flip=False,\n",
    "                             fill_mode = 'nearest')\n",
    "datagen.fit(X_train)\n",
    "# fit parameters from data\n",
    "# datagen.mean = X_train.mean(axis=0)\n",
    "# datagen.std = X_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee4b1c4e-1fa1-4bc4-9c2a-2546c3cbb6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPool2D, BatchNormalization\n",
    "from keras.layers import RandomFlip, RandomRotation\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = 5, activation = 'relu', input_shape = (28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32, kernel_size = 3, activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(98, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(98, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a00183ea-8fa1-4385-8592-bd2ced40a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "92e97957-0a3e-4a11-baba-cec49f490435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11ms/step - accuracy: 0.8421 - loss: 0.5096 - val_accuracy: 0.9845 - val_loss: 0.0475\n",
      "Epoch 2/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9682 - loss: 0.1070 - val_accuracy: 0.9879 - val_loss: 0.0379\n",
      "Epoch 3/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9740 - loss: 0.0826 - val_accuracy: 0.9913 - val_loss: 0.0277\n",
      "Epoch 4/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9779 - loss: 0.0714 - val_accuracy: 0.9943 - val_loss: 0.0188\n",
      "Epoch 5/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9814 - loss: 0.0612 - val_accuracy: 0.9935 - val_loss: 0.0188\n",
      "Epoch 6/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9840 - loss: 0.0547 - val_accuracy: 0.9949 - val_loss: 0.0151\n",
      "Epoch 7/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9852 - loss: 0.0500 - val_accuracy: 0.9957 - val_loss: 0.0139\n",
      "Epoch 8/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9863 - loss: 0.0452 - val_accuracy: 0.9930 - val_loss: 0.0202\n",
      "Epoch 9/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9876 - loss: 0.0414 - val_accuracy: 0.9954 - val_loss: 0.0147\n",
      "Epoch 10/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9878 - loss: 0.0411 - val_accuracy: 0.9946 - val_loss: 0.0179\n",
      "Epoch 11/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9880 - loss: 0.0402 - val_accuracy: 0.9952 - val_loss: 0.0168\n",
      "Epoch 12/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.9893 - loss: 0.0346 - val_accuracy: 0.9958 - val_loss: 0.0138\n",
      "Epoch 13/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9896 - loss: 0.0352 - val_accuracy: 0.9959 - val_loss: 0.0140\n",
      "Epoch 14/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9895 - loss: 0.0353 - val_accuracy: 0.9929 - val_loss: 0.0197\n",
      "Epoch 15/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9898 - loss: 0.0336 - val_accuracy: 0.9951 - val_loss: 0.0169\n",
      "Epoch 16/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9912 - loss: 0.0298 - val_accuracy: 0.9950 - val_loss: 0.0172\n",
      "Epoch 17/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9912 - loss: 0.0300 - val_accuracy: 0.9944 - val_loss: 0.0173\n",
      "Epoch 18/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9904 - loss: 0.0318 - val_accuracy: 0.9954 - val_loss: 0.0149\n",
      "Epoch 19/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9921 - loss: 0.0267 - val_accuracy: 0.9955 - val_loss: 0.0158\n",
      "Epoch 20/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9914 - loss: 0.0291 - val_accuracy: 0.9948 - val_loss: 0.0180\n",
      "Epoch 21/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9914 - loss: 0.0286 - val_accuracy: 0.9964 - val_loss: 0.0133\n",
      "Epoch 22/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0251 - val_accuracy: 0.9957 - val_loss: 0.0150\n",
      "Epoch 23/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9921 - loss: 0.0277 - val_accuracy: 0.9968 - val_loss: 0.0119\n",
      "Epoch 24/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9918 - loss: 0.0271 - val_accuracy: 0.9951 - val_loss: 0.0164\n",
      "Epoch 25/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9934 - loss: 0.0209 - val_accuracy: 0.9957 - val_loss: 0.0152\n",
      "Epoch 26/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9931 - loss: 0.0226 - val_accuracy: 0.9958 - val_loss: 0.0133\n",
      "Epoch 27/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.0235 - val_accuracy: 0.9965 - val_loss: 0.0116\n",
      "Epoch 28/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0222 - val_accuracy: 0.9950 - val_loss: 0.0170\n",
      "Epoch 29/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0216 - val_accuracy: 0.9959 - val_loss: 0.0131\n",
      "Epoch 30/30\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9934 - loss: 0.0218 - val_accuracy: 0.9962 - val_loss: 0.0133\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(datagen.flow(X_train, y_train), validation_data = (X_test, y_test), epochs = 30, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bf7450a1-bf6f-433f-a16e-9b9ab556c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = 5\n",
    "model = [0] *nets\n",
    "for j in range(nets):\n",
    "    model[j] = Sequential()\n",
    "\n",
    "    model[j].add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(32, kernel_size = 3, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Dropout(0.4))\n",
    "\n",
    "    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(64, kernel_size = 3, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Dropout(0.4))\n",
    "\n",
    "    model[j].add(Conv2D(128, kernel_size = 4, activation='relu'))\n",
    "    model[j].add(BatchNormalization())\n",
    "    model[j].add(Flatten())\n",
    "    model[j].add(Dropout(0.4))\n",
    "    model[j].add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\n",
    "    model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "645b9fec-2917-451f-bf49-a7d1f15eaf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "938/938 - 27s - 29ms/step - accuracy: 0.9218 - loss: 0.2542 - val_accuracy: 0.9830 - val_loss: 0.0528 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9730 - loss: 0.0916 - val_accuracy: 0.9933 - val_loss: 0.0204 - learning_rate: 9.5000e-04\n",
      "Epoch 3/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9795 - loss: 0.0671 - val_accuracy: 0.9873 - val_loss: 0.0389 - learning_rate: 9.0250e-04\n",
      "Epoch 4/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9817 - loss: 0.0623 - val_accuracy: 0.9925 - val_loss: 0.0225 - learning_rate: 8.5737e-04\n",
      "Epoch 5/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9840 - loss: 0.0532 - val_accuracy: 0.9916 - val_loss: 0.0259 - learning_rate: 8.1451e-04\n",
      "Epoch 6/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9841 - loss: 0.0509 - val_accuracy: 0.9946 - val_loss: 0.0160 - learning_rate: 7.7378e-04\n",
      "Epoch 7/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9870 - loss: 0.0428 - val_accuracy: 0.9955 - val_loss: 0.0155 - learning_rate: 7.3509e-04\n",
      "Epoch 8/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9880 - loss: 0.0391 - val_accuracy: 0.9917 - val_loss: 0.0260 - learning_rate: 6.9834e-04\n",
      "Epoch 9/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9886 - loss: 0.0378 - val_accuracy: 0.9956 - val_loss: 0.0145 - learning_rate: 6.6342e-04\n",
      "Epoch 10/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9892 - loss: 0.0361 - val_accuracy: 0.9948 - val_loss: 0.0146 - learning_rate: 6.3025e-04\n",
      "Epoch 11/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9905 - loss: 0.0319 - val_accuracy: 0.9965 - val_loss: 0.0116 - learning_rate: 5.9874e-04\n",
      "Epoch 12/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9907 - loss: 0.0316 - val_accuracy: 0.9948 - val_loss: 0.0147 - learning_rate: 5.6880e-04\n",
      "Epoch 13/30\n",
      "938/938 - 14s - 14ms/step - accuracy: 0.9911 - loss: 0.0287 - val_accuracy: 0.9962 - val_loss: 0.0121 - learning_rate: 5.4036e-04\n",
      "Epoch 14/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9916 - loss: 0.0278 - val_accuracy: 0.9962 - val_loss: 0.0127 - learning_rate: 5.1334e-04\n",
      "Epoch 15/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9926 - loss: 0.0247 - val_accuracy: 0.9958 - val_loss: 0.0121 - learning_rate: 4.8767e-04\n",
      "Epoch 16/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9926 - loss: 0.0245 - val_accuracy: 0.9951 - val_loss: 0.0148 - learning_rate: 4.6329e-04\n",
      "Epoch 17/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9936 - loss: 0.0228 - val_accuracy: 0.9965 - val_loss: 0.0110 - learning_rate: 4.4013e-04\n",
      "Epoch 18/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9933 - loss: 0.0216 - val_accuracy: 0.9958 - val_loss: 0.0126 - learning_rate: 4.1812e-04\n",
      "Epoch 19/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9933 - loss: 0.0220 - val_accuracy: 0.9959 - val_loss: 0.0136 - learning_rate: 3.9721e-04\n",
      "Epoch 20/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9935 - loss: 0.0213 - val_accuracy: 0.9961 - val_loss: 0.0124 - learning_rate: 3.7735e-04\n",
      "Epoch 21/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9940 - loss: 0.0203 - val_accuracy: 0.9963 - val_loss: 0.0111 - learning_rate: 3.5849e-04\n",
      "Epoch 22/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9945 - loss: 0.0189 - val_accuracy: 0.9965 - val_loss: 0.0107 - learning_rate: 3.4056e-04\n",
      "Epoch 23/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9941 - loss: 0.0182 - val_accuracy: 0.9959 - val_loss: 0.0121 - learning_rate: 3.2353e-04\n",
      "Epoch 24/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9946 - loss: 0.0175 - val_accuracy: 0.9957 - val_loss: 0.0130 - learning_rate: 3.0736e-04\n",
      "Epoch 25/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9950 - loss: 0.0172 - val_accuracy: 0.9960 - val_loss: 0.0109 - learning_rate: 2.9199e-04\n",
      "Epoch 26/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9948 - loss: 0.0170 - val_accuracy: 0.9967 - val_loss: 0.0113 - learning_rate: 2.7739e-04\n",
      "Epoch 27/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9949 - loss: 0.0161 - val_accuracy: 0.9970 - val_loss: 0.0097 - learning_rate: 2.6352e-04\n",
      "Epoch 28/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9952 - loss: 0.0153 - val_accuracy: 0.9965 - val_loss: 0.0120 - learning_rate: 2.5034e-04\n",
      "Epoch 29/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9952 - loss: 0.0152 - val_accuracy: 0.9967 - val_loss: 0.0108 - learning_rate: 2.3783e-04\n",
      "Epoch 30/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9956 - loss: 0.0143 - val_accuracy: 0.9960 - val_loss: 0.0122 - learning_rate: 2.2594e-04\n",
      "CNN 1: Epochs=30, Train accuracy=0.99565, Validation accuracy=0.99700\n",
      "Epoch 1/30\n",
      "938/938 - 26s - 28ms/step - accuracy: 0.9216 - loss: 0.2575 - val_accuracy: 0.9844 - val_loss: 0.0500 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9725 - loss: 0.0910 - val_accuracy: 0.9915 - val_loss: 0.0251 - learning_rate: 9.5000e-04\n",
      "Epoch 3/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9783 - loss: 0.0707 - val_accuracy: 0.9931 - val_loss: 0.0206 - learning_rate: 9.0250e-04\n",
      "Epoch 4/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9807 - loss: 0.0627 - val_accuracy: 0.9956 - val_loss: 0.0165 - learning_rate: 8.5737e-04\n",
      "Epoch 5/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9838 - loss: 0.0518 - val_accuracy: 0.9943 - val_loss: 0.0171 - learning_rate: 8.1451e-04\n",
      "Epoch 6/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9858 - loss: 0.0477 - val_accuracy: 0.9942 - val_loss: 0.0160 - learning_rate: 7.7378e-04\n",
      "Epoch 7/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9867 - loss: 0.0447 - val_accuracy: 0.9938 - val_loss: 0.0185 - learning_rate: 7.3509e-04\n",
      "Epoch 8/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9870 - loss: 0.0429 - val_accuracy: 0.9932 - val_loss: 0.0203 - learning_rate: 6.9834e-04\n",
      "Epoch 9/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9886 - loss: 0.0382 - val_accuracy: 0.9936 - val_loss: 0.0201 - learning_rate: 6.6342e-04\n",
      "Epoch 10/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9896 - loss: 0.0360 - val_accuracy: 0.9963 - val_loss: 0.0127 - learning_rate: 6.3025e-04\n",
      "Epoch 11/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9900 - loss: 0.0334 - val_accuracy: 0.9958 - val_loss: 0.0146 - learning_rate: 5.9874e-04\n",
      "Epoch 12/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9908 - loss: 0.0303 - val_accuracy: 0.9958 - val_loss: 0.0139 - learning_rate: 5.6880e-04\n",
      "Epoch 13/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9908 - loss: 0.0298 - val_accuracy: 0.9959 - val_loss: 0.0133 - learning_rate: 5.4036e-04\n",
      "Epoch 14/30\n",
      "938/938 - 13s - 13ms/step - accuracy: 0.9920 - loss: 0.0266 - val_accuracy: 0.9955 - val_loss: 0.0131 - learning_rate: 5.1334e-04\n",
      "Epoch 15/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9927 - loss: 0.0252 - val_accuracy: 0.9948 - val_loss: 0.0178 - learning_rate: 4.8767e-04\n",
      "Epoch 16/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9927 - loss: 0.0234 - val_accuracy: 0.9949 - val_loss: 0.0148 - learning_rate: 4.6329e-04\n",
      "Epoch 17/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9930 - loss: 0.0235 - val_accuracy: 0.9969 - val_loss: 0.0105 - learning_rate: 4.4013e-04\n",
      "Epoch 18/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9930 - loss: 0.0234 - val_accuracy: 0.9961 - val_loss: 0.0107 - learning_rate: 4.1812e-04\n",
      "Epoch 19/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9933 - loss: 0.0220 - val_accuracy: 0.9959 - val_loss: 0.0115 - learning_rate: 3.9721e-04\n",
      "Epoch 20/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9941 - loss: 0.0195 - val_accuracy: 0.9960 - val_loss: 0.0116 - learning_rate: 3.7735e-04\n",
      "Epoch 21/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9938 - loss: 0.0186 - val_accuracy: 0.9969 - val_loss: 0.0100 - learning_rate: 3.5849e-04\n",
      "Epoch 22/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9943 - loss: 0.0187 - val_accuracy: 0.9958 - val_loss: 0.0130 - learning_rate: 3.4056e-04\n",
      "Epoch 23/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9945 - loss: 0.0175 - val_accuracy: 0.9964 - val_loss: 0.0105 - learning_rate: 3.2353e-04\n",
      "Epoch 24/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9942 - loss: 0.0188 - val_accuracy: 0.9957 - val_loss: 0.0113 - learning_rate: 3.0736e-04\n",
      "Epoch 25/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9950 - loss: 0.0163 - val_accuracy: 0.9964 - val_loss: 0.0110 - learning_rate: 2.9199e-04\n",
      "Epoch 26/30\n",
      "938/938 - 13s - 13ms/step - accuracy: 0.9950 - loss: 0.0164 - val_accuracy: 0.9962 - val_loss: 0.0098 - learning_rate: 2.7739e-04\n",
      "Epoch 27/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9954 - loss: 0.0158 - val_accuracy: 0.9965 - val_loss: 0.0113 - learning_rate: 2.6352e-04\n",
      "Epoch 28/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9956 - loss: 0.0143 - val_accuracy: 0.9960 - val_loss: 0.0124 - learning_rate: 2.5034e-04\n",
      "Epoch 29/30\n",
      "938/938 - 14s - 14ms/step - accuracy: 0.9957 - loss: 0.0142 - val_accuracy: 0.9962 - val_loss: 0.0109 - learning_rate: 2.3783e-04\n",
      "Epoch 30/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9952 - loss: 0.0147 - val_accuracy: 0.9956 - val_loss: 0.0118 - learning_rate: 2.2594e-04\n",
      "CNN 2: Epochs=30, Train accuracy=0.99572, Validation accuracy=0.99690\n",
      "Epoch 1/30\n",
      "938/938 - 28s - 30ms/step - accuracy: 0.9169 - loss: 0.2703 - val_accuracy: 0.9867 - val_loss: 0.0407 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9739 - loss: 0.0871 - val_accuracy: 0.9916 - val_loss: 0.0273 - learning_rate: 9.5000e-04\n",
      "Epoch 3/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9788 - loss: 0.0711 - val_accuracy: 0.9915 - val_loss: 0.0239 - learning_rate: 9.0250e-04\n",
      "Epoch 4/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9810 - loss: 0.0623 - val_accuracy: 0.9932 - val_loss: 0.0206 - learning_rate: 8.5737e-04\n",
      "Epoch 5/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9829 - loss: 0.0567 - val_accuracy: 0.9941 - val_loss: 0.0187 - learning_rate: 8.1451e-04\n",
      "Epoch 6/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9851 - loss: 0.0503 - val_accuracy: 0.9936 - val_loss: 0.0188 - learning_rate: 7.7378e-04\n",
      "Epoch 7/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9860 - loss: 0.0459 - val_accuracy: 0.9935 - val_loss: 0.0225 - learning_rate: 7.3509e-04\n",
      "Epoch 8/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9878 - loss: 0.0399 - val_accuracy: 0.9936 - val_loss: 0.0181 - learning_rate: 6.9834e-04\n",
      "Epoch 9/30\n",
      "938/938 - 13s - 13ms/step - accuracy: 0.9885 - loss: 0.0383 - val_accuracy: 0.9952 - val_loss: 0.0168 - learning_rate: 6.6342e-04\n",
      "Epoch 10/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9897 - loss: 0.0335 - val_accuracy: 0.9944 - val_loss: 0.0163 - learning_rate: 6.3025e-04\n",
      "Epoch 11/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9897 - loss: 0.0338 - val_accuracy: 0.9953 - val_loss: 0.0151 - learning_rate: 5.9874e-04\n",
      "Epoch 12/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9906 - loss: 0.0299 - val_accuracy: 0.9958 - val_loss: 0.0131 - learning_rate: 5.6880e-04\n",
      "Epoch 13/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9909 - loss: 0.0307 - val_accuracy: 0.9948 - val_loss: 0.0183 - learning_rate: 5.4036e-04\n",
      "Epoch 14/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9910 - loss: 0.0289 - val_accuracy: 0.9962 - val_loss: 0.0129 - learning_rate: 5.1334e-04\n",
      "Epoch 15/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9921 - loss: 0.0266 - val_accuracy: 0.9961 - val_loss: 0.0117 - learning_rate: 4.8767e-04\n",
      "Epoch 16/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9928 - loss: 0.0241 - val_accuracy: 0.9960 - val_loss: 0.0118 - learning_rate: 4.6329e-04\n",
      "Epoch 17/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9930 - loss: 0.0244 - val_accuracy: 0.9953 - val_loss: 0.0139 - learning_rate: 4.4013e-04\n",
      "Epoch 18/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9930 - loss: 0.0225 - val_accuracy: 0.9964 - val_loss: 0.0102 - learning_rate: 4.1812e-04\n",
      "Epoch 19/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9934 - loss: 0.0220 - val_accuracy: 0.9960 - val_loss: 0.0108 - learning_rate: 3.9721e-04\n",
      "Epoch 20/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9937 - loss: 0.0198 - val_accuracy: 0.9964 - val_loss: 0.0100 - learning_rate: 3.7735e-04\n",
      "Epoch 21/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9942 - loss: 0.0188 - val_accuracy: 0.9961 - val_loss: 0.0121 - learning_rate: 3.5849e-04\n",
      "Epoch 22/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9945 - loss: 0.0180 - val_accuracy: 0.9958 - val_loss: 0.0137 - learning_rate: 3.4056e-04\n",
      "Epoch 23/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9940 - loss: 0.0192 - val_accuracy: 0.9963 - val_loss: 0.0121 - learning_rate: 3.2353e-04\n",
      "Epoch 24/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9948 - loss: 0.0170 - val_accuracy: 0.9957 - val_loss: 0.0119 - learning_rate: 3.0736e-04\n",
      "Epoch 25/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9949 - loss: 0.0165 - val_accuracy: 0.9964 - val_loss: 0.0120 - learning_rate: 2.9199e-04\n",
      "Epoch 26/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9948 - loss: 0.0167 - val_accuracy: 0.9963 - val_loss: 0.0121 - learning_rate: 2.7739e-04\n",
      "Epoch 27/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9947 - loss: 0.0170 - val_accuracy: 0.9965 - val_loss: 0.0115 - learning_rate: 2.6352e-04\n",
      "Epoch 28/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9949 - loss: 0.0166 - val_accuracy: 0.9959 - val_loss: 0.0112 - learning_rate: 2.5034e-04\n",
      "Epoch 29/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9953 - loss: 0.0157 - val_accuracy: 0.9966 - val_loss: 0.0111 - learning_rate: 2.3783e-04\n",
      "Epoch 30/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9957 - loss: 0.0139 - val_accuracy: 0.9962 - val_loss: 0.0113 - learning_rate: 2.2594e-04\n",
      "CNN 3: Epochs=30, Train accuracy=0.99573, Validation accuracy=0.99660\n",
      "Epoch 1/30\n",
      "938/938 - 29s - 31ms/step - accuracy: 0.9227 - loss: 0.2534 - val_accuracy: 0.9862 - val_loss: 0.0404 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9732 - loss: 0.0886 - val_accuracy: 0.9918 - val_loss: 0.0262 - learning_rate: 9.5000e-04\n",
      "Epoch 3/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9783 - loss: 0.0704 - val_accuracy: 0.9911 - val_loss: 0.0252 - learning_rate: 9.0250e-04\n",
      "Epoch 4/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9821 - loss: 0.0595 - val_accuracy: 0.9940 - val_loss: 0.0184 - learning_rate: 8.5737e-04\n",
      "Epoch 5/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9832 - loss: 0.0551 - val_accuracy: 0.9949 - val_loss: 0.0185 - learning_rate: 8.1451e-04\n",
      "Epoch 6/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9856 - loss: 0.0485 - val_accuracy: 0.9935 - val_loss: 0.0211 - learning_rate: 7.7378e-04\n",
      "Epoch 7/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9866 - loss: 0.0429 - val_accuracy: 0.9929 - val_loss: 0.0234 - learning_rate: 7.3509e-04\n",
      "Epoch 8/30\n",
      "938/938 - 14s - 14ms/step - accuracy: 0.9868 - loss: 0.0428 - val_accuracy: 0.9934 - val_loss: 0.0218 - learning_rate: 6.9834e-04\n",
      "Epoch 9/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9886 - loss: 0.0383 - val_accuracy: 0.9952 - val_loss: 0.0165 - learning_rate: 6.6342e-04\n",
      "Epoch 10/30\n",
      "938/938 - 14s - 14ms/step - accuracy: 0.9893 - loss: 0.0346 - val_accuracy: 0.9955 - val_loss: 0.0145 - learning_rate: 6.3025e-04\n",
      "Epoch 11/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9904 - loss: 0.0316 - val_accuracy: 0.9948 - val_loss: 0.0142 - learning_rate: 5.9874e-04\n",
      "Epoch 12/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9911 - loss: 0.0298 - val_accuracy: 0.9937 - val_loss: 0.0204 - learning_rate: 5.6880e-04\n",
      "Epoch 13/30\n",
      "938/938 - 14s - 14ms/step - accuracy: 0.9906 - loss: 0.0310 - val_accuracy: 0.9958 - val_loss: 0.0132 - learning_rate: 5.4036e-04\n",
      "Epoch 14/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9916 - loss: 0.0271 - val_accuracy: 0.9954 - val_loss: 0.0145 - learning_rate: 5.1334e-04\n",
      "Epoch 15/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9919 - loss: 0.0266 - val_accuracy: 0.9962 - val_loss: 0.0132 - learning_rate: 4.8767e-04\n",
      "Epoch 16/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9923 - loss: 0.0251 - val_accuracy: 0.9951 - val_loss: 0.0169 - learning_rate: 4.6329e-04\n",
      "Epoch 17/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9927 - loss: 0.0236 - val_accuracy: 0.9957 - val_loss: 0.0156 - learning_rate: 4.4013e-04\n",
      "Epoch 18/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9936 - loss: 0.0214 - val_accuracy: 0.9954 - val_loss: 0.0136 - learning_rate: 4.1812e-04\n",
      "Epoch 19/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9938 - loss: 0.0199 - val_accuracy: 0.9962 - val_loss: 0.0123 - learning_rate: 3.9721e-04\n",
      "Epoch 20/30\n",
      "938/938 - 16s - 18ms/step - accuracy: 0.9937 - loss: 0.0206 - val_accuracy: 0.9957 - val_loss: 0.0144 - learning_rate: 3.7735e-04\n",
      "Epoch 21/30\n",
      "938/938 - 15s - 16ms/step - accuracy: 0.9938 - loss: 0.0203 - val_accuracy: 0.9959 - val_loss: 0.0134 - learning_rate: 3.5849e-04\n",
      "Epoch 22/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9944 - loss: 0.0186 - val_accuracy: 0.9955 - val_loss: 0.0139 - learning_rate: 3.4056e-04\n",
      "Epoch 23/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9945 - loss: 0.0185 - val_accuracy: 0.9959 - val_loss: 0.0130 - learning_rate: 3.2353e-04\n",
      "Epoch 24/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9946 - loss: 0.0179 - val_accuracy: 0.9966 - val_loss: 0.0118 - learning_rate: 3.0736e-04\n",
      "Epoch 25/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9951 - loss: 0.0161 - val_accuracy: 0.9944 - val_loss: 0.0170 - learning_rate: 2.9199e-04\n",
      "Epoch 26/30\n",
      "938/938 - 14s - 14ms/step - accuracy: 0.9950 - loss: 0.0159 - val_accuracy: 0.9960 - val_loss: 0.0129 - learning_rate: 2.7739e-04\n",
      "Epoch 27/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9949 - loss: 0.0160 - val_accuracy: 0.9965 - val_loss: 0.0113 - learning_rate: 2.6352e-04\n",
      "Epoch 28/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9951 - loss: 0.0153 - val_accuracy: 0.9963 - val_loss: 0.0134 - learning_rate: 2.5034e-04\n",
      "Epoch 29/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9952 - loss: 0.0148 - val_accuracy: 0.9963 - val_loss: 0.0125 - learning_rate: 2.3783e-04\n",
      "Epoch 30/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9958 - loss: 0.0141 - val_accuracy: 0.9961 - val_loss: 0.0134 - learning_rate: 2.2594e-04\n",
      "CNN 4: Epochs=30, Train accuracy=0.99578, Validation accuracy=0.99660\n",
      "Epoch 1/30\n",
      "938/938 - 28s - 30ms/step - accuracy: 0.9179 - loss: 0.2703 - val_accuracy: 0.9849 - val_loss: 0.0432 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9727 - loss: 0.0909 - val_accuracy: 0.9889 - val_loss: 0.0370 - learning_rate: 9.5000e-04\n",
      "Epoch 3/30\n",
      "938/938 - 14s - 14ms/step - accuracy: 0.9787 - loss: 0.0716 - val_accuracy: 0.9933 - val_loss: 0.0208 - learning_rate: 9.0250e-04\n",
      "Epoch 4/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9810 - loss: 0.0641 - val_accuracy: 0.9929 - val_loss: 0.0219 - learning_rate: 8.5737e-04\n",
      "Epoch 5/30\n",
      "938/938 - 14s - 14ms/step - accuracy: 0.9826 - loss: 0.0562 - val_accuracy: 0.9941 - val_loss: 0.0217 - learning_rate: 8.1451e-04\n",
      "Epoch 6/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9847 - loss: 0.0501 - val_accuracy: 0.9938 - val_loss: 0.0187 - learning_rate: 7.7378e-04\n",
      "Epoch 7/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9855 - loss: 0.0471 - val_accuracy: 0.9923 - val_loss: 0.0235 - learning_rate: 7.3509e-04\n",
      "Epoch 8/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9870 - loss: 0.0428 - val_accuracy: 0.9948 - val_loss: 0.0162 - learning_rate: 6.9834e-04\n",
      "Epoch 9/30\n",
      "938/938 - 14s - 14ms/step - accuracy: 0.9891 - loss: 0.0369 - val_accuracy: 0.9945 - val_loss: 0.0183 - learning_rate: 6.6342e-04\n",
      "Epoch 10/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9893 - loss: 0.0362 - val_accuracy: 0.9960 - val_loss: 0.0155 - learning_rate: 6.3025e-04\n",
      "Epoch 11/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9900 - loss: 0.0326 - val_accuracy: 0.9963 - val_loss: 0.0135 - learning_rate: 5.9874e-04\n",
      "Epoch 12/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9907 - loss: 0.0316 - val_accuracy: 0.9954 - val_loss: 0.0143 - learning_rate: 5.6880e-04\n",
      "Epoch 13/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9907 - loss: 0.0303 - val_accuracy: 0.9934 - val_loss: 0.0209 - learning_rate: 5.4036e-04\n",
      "Epoch 14/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9911 - loss: 0.0300 - val_accuracy: 0.9961 - val_loss: 0.0138 - learning_rate: 5.1334e-04\n",
      "Epoch 15/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9920 - loss: 0.0254 - val_accuracy: 0.9953 - val_loss: 0.0140 - learning_rate: 4.8767e-04\n",
      "Epoch 16/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9917 - loss: 0.0269 - val_accuracy: 0.9953 - val_loss: 0.0140 - learning_rate: 4.6329e-04\n",
      "Epoch 17/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9929 - loss: 0.0236 - val_accuracy: 0.9960 - val_loss: 0.0121 - learning_rate: 4.4013e-04\n",
      "Epoch 18/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9931 - loss: 0.0226 - val_accuracy: 0.9963 - val_loss: 0.0120 - learning_rate: 4.1812e-04\n",
      "Epoch 19/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9933 - loss: 0.0222 - val_accuracy: 0.9963 - val_loss: 0.0125 - learning_rate: 3.9721e-04\n",
      "Epoch 20/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9935 - loss: 0.0210 - val_accuracy: 0.9964 - val_loss: 0.0121 - learning_rate: 3.7735e-04\n",
      "Epoch 21/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9934 - loss: 0.0210 - val_accuracy: 0.9967 - val_loss: 0.0108 - learning_rate: 3.5849e-04\n",
      "Epoch 22/30\n",
      "938/938 - 14s - 14ms/step - accuracy: 0.9942 - loss: 0.0192 - val_accuracy: 0.9957 - val_loss: 0.0133 - learning_rate: 3.4056e-04\n",
      "Epoch 23/30\n",
      "938/938 - 15s - 16ms/step - accuracy: 0.9943 - loss: 0.0188 - val_accuracy: 0.9970 - val_loss: 0.0111 - learning_rate: 3.2353e-04\n",
      "Epoch 24/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9941 - loss: 0.0191 - val_accuracy: 0.9968 - val_loss: 0.0113 - learning_rate: 3.0736e-04\n",
      "Epoch 25/30\n",
      "938/938 - 15s - 16ms/step - accuracy: 0.9945 - loss: 0.0171 - val_accuracy: 0.9966 - val_loss: 0.0107 - learning_rate: 2.9199e-04\n",
      "Epoch 26/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9950 - loss: 0.0170 - val_accuracy: 0.9976 - val_loss: 0.0102 - learning_rate: 2.7739e-04\n",
      "Epoch 27/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9954 - loss: 0.0146 - val_accuracy: 0.9968 - val_loss: 0.0108 - learning_rate: 2.6352e-04\n",
      "Epoch 28/30\n",
      "938/938 - 13s - 14ms/step - accuracy: 0.9955 - loss: 0.0154 - val_accuracy: 0.9966 - val_loss: 0.0113 - learning_rate: 2.5034e-04\n",
      "Epoch 29/30\n",
      "938/938 - 13s - 13ms/step - accuracy: 0.9957 - loss: 0.0145 - val_accuracy: 0.9967 - val_loss: 0.0118 - learning_rate: 2.3783e-04\n",
      "Epoch 30/30\n",
      "938/938 - 14s - 15ms/step - accuracy: 0.9956 - loss: 0.0140 - val_accuracy: 0.9970 - val_loss: 0.0108 - learning_rate: 2.2594e-04\n",
      "CNN 5: Epochs=30, Train accuracy=0.99567, Validation accuracy=0.99760\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "# DECREASE LEARNING RATE EACH EPOCH\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)\n",
    "# TRAIN NETWORKS\n",
    "history = [0] * nets\n",
    "epochs = 30\n",
    "for j in range(nets):\n",
    "    history[j] = model[j].fit(datagen.flow(X_train,y_train, batch_size=64),\n",
    "        epochs = epochs, validation_data = (X_test,y_test), callbacks=[annealer], verbose=2)\n",
    "    print(\"CNN {0:d}: Epochs={1:d}, Train accuracy={2:.5f}, Validation accuracy={3:.5f}\".format(\n",
    "        j+1,epochs,max(history[j].history['accuracy']),max(history[j].history['val_accuracy']) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "db85ed47-6c53-4250-ae93-555e30b981ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model \n",
    "from keras.layers import Input\n",
    "from keras import layers\n",
    "\n",
    "def ensembleModels(models, model_input):\n",
    "    # collect outputs of models in a list\n",
    "    yModels=[model(model_input) for model in models] \n",
    "    # averaging outputs\n",
    "    yAvg=layers.average(yModels) \n",
    "    # build model from same input and avg output\n",
    "    modelEns = Model(inputs=model_input, outputs=yAvg,    name='ensemble_model')  \n",
    "   \n",
    "    return modelEns\n",
    "\n",
    "for mod in model:\n",
    "    \n",
    "model_input = Input(shape=model[0].input_shape[1:]) # c*h*w\n",
    "modelEns = ensembleModels(model, model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d6d09bd4-91f9-4d8c-9bbf-81eb2918d68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
      "Percentage misclassified =  0.28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "outputs=modelEns.predict(X_test)\n",
    "labels_predicted=np.argmax(outputs, axis=1) \n",
    "misclassified=sum(labels_predicted!=labels_test) \n",
    "print('Percentage misclassified = ',100*misclassified/labels_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6ae408ff-a0e0-431e-b531-960c3a745f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ensemble\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ensemble\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_52      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_44       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">327,242</span> │ input_layer_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_45       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">327,242</span> │ input_layer_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_46       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">327,242</span> │ input_layer_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_47       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">327,242</span> │ input_layer_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_48       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">327,242</span> │ input_layer_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Average</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ sequential_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ sequential_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ sequential_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ sequential_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_52      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_44       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │    \u001b[38;5;34m327,242\u001b[0m │ input_layer_52[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_45       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │    \u001b[38;5;34m327,242\u001b[0m │ input_layer_52[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_46       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │    \u001b[38;5;34m327,242\u001b[0m │ input_layer_52[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_47       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │    \u001b[38;5;34m327,242\u001b[0m │ input_layer_52[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_48       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │    \u001b[38;5;34m327,242\u001b[0m │ input_layer_52[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ average_1 (\u001b[38;5;33mAverage\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ sequential_44[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ sequential_45[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ sequential_46[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ sequential_47[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ sequential_48[\u001b[38;5;34m0\u001b[0m]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,636,210</span> (6.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,636,210\u001b[0m (6.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,632,050</span> (6.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,632,050\u001b[0m (6.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> (16.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,160\u001b[0m (16.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelEns.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aa9680b9-f0b8-40bd-a028-9c0e390e0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(modelEns.weights)):\n",
    "    modelEns.weights[i]._handle_name = modelEns.weights[i].name + \"_\" + str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "02ee7925-edcb-4b43-8a72-3cd4d23d405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "18c5345c-b294-4911-9eb6-a5a67fd3d405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to synchronously create dataset (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodelEns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemp.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/group.py:183\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    180\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    181\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[0;32m--> 183\u001b[0m dsid \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_new_dset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/dataset.py:163\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     sid \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(shape, maxshape)\n\u001b[0;32m--> 163\u001b[0m dset_id \u001b[38;5;241m=\u001b[39m \u001b[43mh5d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Empty)):\n\u001b[1;32m    166\u001b[0m     dset_id\u001b[38;5;241m.\u001b[39mwrite(h5s\u001b[38;5;241m.\u001b[39mALL, h5s\u001b[38;5;241m.\u001b[39mALL, data)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5d.pyx:137\u001b[0m, in \u001b[0;36mh5py.h5d.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to synchronously create dataset (name already exists)"
     ]
    }
   ],
   "source": [
    "modelEns.save('temp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a882a9a6-a13e-42a0-ac6f-eb503d9edd9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
